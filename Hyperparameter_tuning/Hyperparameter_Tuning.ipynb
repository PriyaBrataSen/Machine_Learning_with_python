{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for xgboost model \n",
    "\n",
    "### 1. Grid Search\n",
    "### 2. Random Search\n",
    "### 3. Bayesian Optimization\n",
    "### 4. Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, RandomizedSearchCV,TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform, randint\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "from tpot import TPOTRegressor\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('llama_forecast_train.csv')\n",
    "df2=pd.read_csv('historical_weather.csv')\n",
    "df2.rename(columns={'HOUR':'DAY'},inplace='True')\n",
    "df1=pd.merge(df1,df2,on=['DAY'], how= \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting date features from the training data\n",
    "df1['Date']=pd.to_datetime(df1['DAY'])\n",
    "df1.sort_values(by='Date',ascending=True,inplace=True)\n",
    "df1['Year']=df1['Date'].dt.year\n",
    "df1['Month']=df1['Date'].dt.month\n",
    "df1['Week']=df1['Date'].dt.week\n",
    "df1['Day']=df1['Date'].dt.day\n",
    "df1['Week Day']=df1['Date'].dt.dayofweek\n",
    "df1['Year Day']=df1['Date'].dt.dayofyear\n",
    "df1.drop(['Date','DAY'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HABITAT ID</th>\n",
       "      <th>AVAILABLE LLAMAS</th>\n",
       "      <th>TEMPERATURE</th>\n",
       "      <th>HUMIDITY</th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>WINDSPEED</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>...</th>\n",
       "      <th>HABITAT NAME_Peachtree</th>\n",
       "      <th>HABITAT NAME_Perfect Square</th>\n",
       "      <th>HABITAT NAME_Primary Cay</th>\n",
       "      <th>HABITAT NAME_Pulp Point</th>\n",
       "      <th>HABITAT NAME_Random Forest</th>\n",
       "      <th>HABITAT NAME_Ridge Road</th>\n",
       "      <th>HABITAT NAME_Shortest Path</th>\n",
       "      <th>HABITAT NAME_Tierra del Fuego</th>\n",
       "      <th>HABITAT NAME_Vector Field</th>\n",
       "      <th>HABITAT NAME_Wildcat Way</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>96</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>88</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HABITAT ID  AVAILABLE LLAMAS  TEMPERATURE  HUMIDITY  PRECIPITATION  \\\n",
       "0           0                74           73        71            0.0   \n",
       "1          18                58           73        71            0.0   \n",
       "2          20                96           73        71            0.0   \n",
       "3          22                88           73        71            0.0   \n",
       "4           7                48           73        71            0.0   \n",
       "\n",
       "   WINDSPEED  Year  Month  Week  Day  ...  HABITAT NAME_Peachtree  \\\n",
       "0        9.4  2017      7    26    1  ...                       1   \n",
       "1        9.4  2017      7    26    1  ...                       0   \n",
       "2        9.4  2017      7    26    1  ...                       0   \n",
       "3        9.4  2017      7    26    1  ...                       0   \n",
       "4        9.4  2017      7    26    1  ...                       0   \n",
       "\n",
       "   HABITAT NAME_Perfect Square  HABITAT NAME_Primary Cay  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            1                         0   \n",
       "\n",
       "   HABITAT NAME_Pulp Point  HABITAT NAME_Random Forest  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   HABITAT NAME_Ridge Road  HABITAT NAME_Shortest Path  \\\n",
       "0                        0                           0   \n",
       "1                        0                           1   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "\n",
       "   HABITAT NAME_Tierra del Fuego  HABITAT NAME_Vector Field  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          1   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   HABITAT NAME_Wildcat Way  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.concat([df1, pd.get_dummies(df1[['HABITAT NAME']])], axis=1).drop(['HABITAT NAME'],axis=1)\n",
    "df3=df3.reset_index(drop=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df3['AVAILABLE LLAMAS']\n",
    "x=df3.drop(['AVAILABLE LLAMAS'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "model=xgb.XGBRegressor(objective ='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.41276388732124"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "b=int(len(df1)*.75)\n",
    "x_train, x_test=x.iloc[0:b, :], x.iloc[b:-1, :]\n",
    "y_train, y_test=y.iloc[0:b], y.iloc[b:-1]\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#Function to calculate rmse after doing hyperparameter optimization\n",
    "\n",
    "def result(model):\n",
    "    y_pred=model.predict(x_test)\n",
    "    mse=mean_squared_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mse)\n",
    "    return rmse\n",
    "    \n",
    "    \n",
    "result(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data for hyperparameter tuning\n",
    "tss=TimeSeriesSplit(n_splits=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5,\n",
      " 'booster': 'gbtree',\n",
      " 'colsample_bylevel': 1,\n",
      " 'colsample_bynode': 1,\n",
      " 'colsample_bytree': 1,\n",
      " 'gamma': 0,\n",
      " 'gpu_id': -1,\n",
      " 'interaction_constraints': '',\n",
      " 'learning_rate': 0.300000012,\n",
      " 'max_delta_step': 0,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 1,\n",
      " 'monotone_constraints': '()',\n",
      " 'n_jobs': 0,\n",
      " 'num_parallel_tree': 1,\n",
      " 'objective': 'reg:squarederror',\n",
      " 'random_state': 0,\n",
      " 'reg_alpha': 0,\n",
      " 'reg_lambda': 1,\n",
      " 'scale_pos_weight': 1,\n",
      " 'subsample': 1,\n",
      " 'tree_method': 'exact',\n",
      " 'validate_parameters': 1,\n",
      " 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "pprint(model.get_xgb_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints='',\n",
       "                                    learning_rate=0.300000012, max_delta_step=0,\n",
       "                                    max_depth=6, min_child_weight=1,\n",
       "                                    missing=na...\n",
       "                                    num_parallel_tree=1, random_state=0,\n",
       "                                    reg_alpha=0, reg_lambda=1,\n",
       "                                    scale_pos_weight=1, subsample=1,\n",
       "                                    tree_method='exact', validate_parameters=1,\n",
       "                                    verbosity=None),\n",
       "             n_jobs=1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1], 'max_depth': [2, 4, 6],\n",
       "                         'min_child_weight': [1, 3],\n",
       "                         'n_estimators': [10, 100, 150], 'reg_alpha': [1, 3],\n",
       "                         'reg_lambda': [1, 3], 'subsample': [0.8, 1]},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the grid\n",
    "params = {\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\": [2, 4, 6],\n",
    "    \"n_estimators\": [10, 100,150],\n",
    "    \"subsample\": [0.8, 1],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"reg_lambda\": [1, 3],\n",
    "    \"reg_alpha\": [1, 3]\n",
    "}\n",
    "\n",
    "# setup the grid search\n",
    "grid_search = GridSearchCV(model,\n",
    "                           param_grid=params,\n",
    "                           cv=tss,\n",
    "                           verbose=1,\n",
    "                           n_jobs=1,\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 100,\n",
       " 'reg_alpha': 3,\n",
       " 'reg_lambda': 3,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.389818301906804"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          gpu_id=-1, importance_type='gain',\n",
       "                                          interaction_constraints='',\n",
       "                                          learning_rate=0.300000012,\n",
       "                                          max_delta_step=0, max_depth=6,\n",
       "                                          min_child_weight=1, miss...\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023621E25C48>,\n",
       "                                        'reg_alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023621E311C8>,\n",
       "                                        'reg_lambda': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023621E2BD08>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000236204EA388>},\n",
       "                   random_state=8675309, return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.5, 1.],\n",
    "    \"max_depth\": randint(1, 30),\n",
    "    \"n_estimators\": randint(10, 250),\n",
    "    \"subsample\": uniform(0.05, 0.95),  # so uniform on [.05,.05+.95] = [.05,1.]\n",
    "    \"min_child_weight\": randint(1, 30),\n",
    "    \"reg_alpha\": uniform(0, 10),\n",
    "    \"reg_lambda\": uniform(0, 10)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=params,\n",
    "    random_state=8675309,\n",
    "    n_iter=200,\n",
    "    cv=tss,\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    "    return_train_score=True)\n",
    "\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5,\n",
       " 'max_depth': 16,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 59,\n",
       " 'reg_alpha': 8.507781740418231,\n",
       " 'reg_lambda': 7.697186827516576,\n",
       " 'subsample': 0.37389972137581645}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.604058381553173"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 2.57s\n",
      "num acquisition: 2, time elapsed: 5.19s\n",
      "num acquisition: 3, time elapsed: 8.01s\n",
      "num acquisition: 4, time elapsed: 10.54s\n",
      "num acquisition: 5, time elapsed: 13.00s\n",
      "num acquisition: 6, time elapsed: 15.61s\n",
      "num acquisition: 7, time elapsed: 17.97s\n",
      "num acquisition: 8, time elapsed: 20.35s\n",
      "num acquisition: 9, time elapsed: 22.82s\n",
      "num acquisition: 10, time elapsed: 24.76s\n",
      "num acquisition: 11, time elapsed: 27.10s\n",
      "num acquisition: 12, time elapsed: 29.60s\n",
      "num acquisition: 13, time elapsed: 32.03s\n",
      "num acquisition: 14, time elapsed: 34.71s\n",
      "num acquisition: 15, time elapsed: 36.86s\n",
      "num acquisition: 16, time elapsed: 39.47s\n",
      "num acquisition: 17, time elapsed: 42.54s\n",
      "num acquisition: 18, time elapsed: 45.65s\n",
      "num acquisition: 19, time elapsed: 48.33s\n",
      "num acquisition: 20, time elapsed: 50.93s\n"
     ]
    }
   ],
   "source": [
    "# unfold to see code\n",
    "np.random.seed(8675309)  # seed courtesy of Tommy Tutone\n",
    "# from GPyOpt.methods import BayesianOptimization\n",
    "# from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "hp_bounds = [{\n",
    "    'name': 'learning_rate',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0.001, 1.0)\n",
    "}, {\n",
    "    'name': 'max_depth',\n",
    "    'type': 'discrete',\n",
    "    'domain': (1, 10)\n",
    "}, {\n",
    "    'name': 'n_estimators',\n",
    "    'type': 'discrete',\n",
    "    'domain': (10, 150)\n",
    "}, {\n",
    "    'name': 'subsample',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0.05, 1.0)\n",
    "}, {\n",
    "    'name': 'min_child_weight',\n",
    "    'type': 'discrete',\n",
    "    'domain': (1, 20)\n",
    "}, {\n",
    "    'name': 'reg_alpha',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0, 5)\n",
    "}, {\n",
    "    'name': 'reg_lambda',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0, 5)\n",
    "}]\n",
    "\n",
    "\n",
    "# Optimization objective\n",
    "def cv_score(hyp_parameters):\n",
    "    hyp_parameters = hyp_parameters[0]\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                                 learning_rate=hyp_parameters[0],\n",
    "                                 max_depth=int(hyp_parameters[1]),\n",
    "                                 n_estimators=int(hyp_parameters[2]),\n",
    "                                 subsample=hyp_parameters[3],\n",
    "                                 min_child_weight=int(hyp_parameters[4]),\n",
    "                                 reg_alpha=hyp_parameters[5],\n",
    "                                 reg_lambda=hyp_parameters[6])\n",
    "    scores = cross_val_score(model,\n",
    "                             X=x_train,\n",
    "                             y=y_train,\n",
    "                             cv=tss)\n",
    "    return np.array(scores.mean())  # return average of 5-fold scores\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_score,\n",
    "                                 domain=hp_bounds,\n",
    "                                 model_type='GP',\n",
    "                                 acquisition_type='EI',\n",
    "                                 acquisition_jitter=0.05,\n",
    "                                 exact_feval=True,\n",
    "                                 maximize=True,\n",
    "                                 verbosity=True)\n",
    "\n",
    "optimizer.run_optimization(max_iter=20,verbosity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.35488033434114763,\n",
       " 'max_depth': 10,\n",
       " 'n_estimators': 10,\n",
       " 'subsample': 0.5687129957781784,\n",
       " 'min_child_weight': 1,\n",
       " 'reg_alpha': 3.950325217852195,\n",
       " 'reg_lambda': 0.2536401881692735}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyp_set = {}\n",
    "for i in range(len(hp_bounds)):\n",
    "    if hp_bounds[i]['type'] == 'continuous':\n",
    "        best_hyp_set[hp_bounds[i]['name']] = optimizer.x_opt[i]\n",
    "    else:\n",
    "        best_hyp_set[hp_bounds[i]['name']] = int(optimizer.x_opt[i])\n",
    "best_hyp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.795493176431403"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayopt_search = xgb.XGBRegressor(objective='reg:squarederror',**best_hyp_set)\n",
    "bayopt_search.fit(x_train,y_train)\n",
    "result(bayopt_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Genetic Algorithm from TPOT library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=1020, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8164448565204342\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8183018885515837\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8183018885515837\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.8183018885515837\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.818586428023087\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.8201404698660323\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.8201404698660323\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.8201404698660323\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.8201404698660323\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.8201404698660323\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.8201404698660323\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.8201404698660323\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 15 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 16 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 17 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 18 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 19 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 20 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 21 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 22 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 23 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 24 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 25 - Current best internal CV score: 0.8244763501210377\n",
      "\n",
      "Generation 26 - Current best internal CV score: 0.8292897691945691\n",
      "\n",
      "Generation 27 - Current best internal CV score: 0.8292897691945691\n",
      "\n",
      "Generation 28 - Current best internal CV score: 0.8292897691945691\n",
      "\n",
      "Generation 29 - Current best internal CV score: 0.8340206755341198\n",
      "\n",
      "Generation 30 - Current best internal CV score: 0.8340206755341198\n",
      "\n",
      "Generation 31 - Current best internal CV score: 0.8340206755341198\n",
      "\n",
      "Generation 32 - Current best internal CV score: 0.8340206755341198\n",
      "\n",
      "Generation 33 - Current best internal CV score: 0.8340206755341198\n",
      "\n",
      "Generation 34 - Current best internal CV score: 0.8355250996513472\n",
      "\n",
      "Generation 35 - Current best internal CV score: 0.8355250996513472\n",
      "\n",
      "Generation 36 - Current best internal CV score: 0.8395181320329858\n",
      "\n",
      "Generation 37 - Current best internal CV score: 0.8395181320329858\n",
      "\n",
      "Generation 38 - Current best internal CV score: 0.8395181320329858\n",
      "\n",
      "Generation 39 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 40 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 41 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 42 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 43 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 44 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 45 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 46 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 47 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 48 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 49 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Generation 50 - Current best internal CV score: 0.8432796425554977\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=1.0, max_depth=3, min_child_weight=3, n_estimators=100, nthread=1, objective=reg:squarederror, reg_alpha=4.25, reg_lambda=4.5, subsample=0.55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict={'xgboost.XGBRegressor': {'learning_rate': array([0.001, 0.01 , 0.05 , 0.1  , 0.15 , 0.2  , 0.25 , 0.3  , 0.35 ,\n",
       "       0.4  , 0.45 , 0.5  , 0.55 , 0.6  , 0.65 , 0.7  , 0.75 , 0.8  ,\n",
       "       0.85 , 0.9  , 0.95 , 1.   ]),\n",
       "                                                    'max_depth': range(1, 11),\n",
       "                                                    'min_child_weight': range(1, 21),\n",
       "                                                    'n_estimators': [100],\n",
       "                                                    'nthread': [1],\n",
       "                                                    'objective': ['reg:squarederror'],\n",
       "                                                    'reg_alpha': array([1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.7...\n",
       "                                                    'reg_lambda': array([1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 , 2.75, 3.  , 3.25, 3.5 ,\n",
       "       3.75, 4.  , 4.25, 4.5 , 4.75, 5.  ]),\n",
       "                                                    'subsample': array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])}},\n",
       "              cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None),\n",
       "              generations=50, population_size=20, random_state=8675309,\n",
       "              scoring='r2', template='Regressor', verbosity=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from tpot import TPOTRegressor\n",
    "\n",
    "tpot_config = {\n",
    "    'xgboost.XGBRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 11),\n",
    "        'learning_rate': np.append(np.array([.001,.01]),np.arange(0.05,1.05,.05)),\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'reg_alpha': np.arange(1.0,5.25,.25),\n",
    "        'reg_lambda': np.arange(1.0,5.25,.25),\n",
    "        'nthread': [1],\n",
    "        'objective': ['reg:squarederror']\n",
    "    }\n",
    "}\n",
    "\n",
    "tpot = TPOTRegressor(scoring = 'r2',\n",
    "                     generations=50,\n",
    "                     population_size=20,\n",
    "                     verbosity=2,\n",
    "                     config_dict=tpot_config,\n",
    "                     cv=tss,\n",
    "                     template='Regressor', #no stacked models\n",
    "                     random_state=8675309)\n",
    "\n",
    "tpot.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.869062596452192"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result(tpot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Regular Model</td>\n",
       "      <td>23.412764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grid Search</td>\n",
       "      <td>22.389818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random_Search</td>\n",
       "      <td>24.604058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bayesian Optimization</td>\n",
       "      <td>23.795493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genetic Algorithm</td>\n",
       "      <td>27.869063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model       RMSE\n",
       "0          Regular Model  23.412764\n",
       "1            Grid Search  22.389818\n",
       "2          Random_Search  24.604058\n",
       "3  Bayesian Optimization  23.795493\n",
       "4      Genetic Algorithm  27.869063"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize list of lists\n",
    "data = [['Regular Model', result(model)], ['Grid Search', result(grid_search)], ['Random_Search', result(random_search)], ['Bayesian Optimization', result(bayopt_search)], ['Genetic Algorithm', result(tpot)]]\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(data, columns = ['Model', 'RMSE'])\n",
    "  \n",
    "# print dataframe.\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see Grid Seach gave use the best RMSE for this dataset. It is better to try all the approaches to see which one optimize the final accuracy !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
