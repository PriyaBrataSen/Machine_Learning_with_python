{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PSEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PSEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict,GridSearchCV,StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix,accuracy_score,classification_report\n",
    "#py.offline.init_notebook_mode(connected=True)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df=df.rename(columns={'id':'id','keyword':'keyword','location':'location','text':'text','target':'target'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "def process(s):\n",
    "    #s = re.sub(r'[0-9]+', '', s)\n",
    "    s = re.sub(r'@\\w+', '', s)\n",
    "    s = re.sub(r'http\\w+', '', s)\n",
    "    s = re.sub(r'www.[^ ]+', '', s)\n",
    "    #s = re.sub(r'[\\W\\_]', ' ', s)\n",
    "    s = re.sub(r'''[Â¬!\"#$%&()*+,-./:;<=>?@[\\]'^'_`\\{|}~]''', '', s)\n",
    "    return s.lower()\n",
    "\n",
    "def stop_word(words):\n",
    "    token=re.split('\\W+',words)\n",
    "    txt=[word for word in token if word not in stop_words]\n",
    "    return txt\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatization(words):\n",
    "    txt=[lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in words]\n",
    "    return txt\n",
    "\n",
    "def final_text(words):\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def model_union(transfomer_numeric,transformer_text,X,y):\n",
    "    pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', transfomer_numeric)\n",
    "            ])),\n",
    "            ('text_features', Pipeline([\n",
    "                ('selector', transformer_text),\n",
    "                ('vec', TfidfVectorizer(analyzer='word'))\n",
    "            ]))\n",
    "        ])),\n",
    "    ('clf', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "    # Grid Search Parameters for RandomForest\n",
    "    # param_grid = {'clf__n_estimators': np.linspace(1, 100, 10, dtype=int),\n",
    "    #             'clf__min_samples_split': [3, 10],\n",
    "    #             'clf__min_samples_leaf': [3],\n",
    "    #             'clf__max_features': [7],\n",
    "    #             'clf__max_depth': [None],\n",
    "    #             'clf__criterion': ['gini'],\n",
    "    #             'clf__bootstrap': [False]}\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=3)\n",
    "    scoring = {'Accuracy': 'accuracy', 'F1': 'f1_macro'}\n",
    "    refit = 'F1'\n",
    "\n",
    "\n",
    "    # rf_model = GridSearchCV(pipeline, param_grid=param_grid, cv=kfold, scoring=scoring,refit=refit, n_jobs=-1, return_train_score=True, verbose=1)\n",
    "    # rf_model.fit(X, y)\n",
    "    # rf_best = rf_model.best_estimator_\n",
    "\n",
    "    score=cross_val_score(pipeline,X=X,y=y,cv=kfold,scoring='accuracy')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['modified_text']=df['text'].apply(lambda x: process(x)).apply(lambda x: stop_word(x)).apply(lambda x: lemmatization(x)).apply(lambda x: final_text(x))\n",
    "df=df[['id','keyword','location','text','modified_text','target']]\n",
    "df['word_count'] = df['modified_text'].apply(lambda x: len(x.split()))\n",
    "df['unique_word_count'] = df['modified_text'].apply(lambda x: len(set(x.split())))\n",
    "df['mean_word_len'] = df['modified_text'].apply(lambda x: np.mean([len(w) for w in x.split()]))\n",
    "df['char_count']=df['modified_text'].apply(lambda x: len(x))\n",
    "df1=df[['target','modified_text']]\n",
    "df2=df.drop(['id','keyword','location','text'],axis=1)[['target','modified_text','word_count','unique_word_count','mean_word_len','char_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>modified_text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>get sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                       modified_text  target  word_count  \\\n",
       "0         deed reason earthquake may allah forgive u       1           7   \n",
       "1              forest fire near la ronge sask canada       1           7   \n",
       "2  resident ask shelter place notify officer evac...       1          11   \n",
       "3  13000 people receive wildfire evacuation order...       1           7   \n",
       "4  get sent photo ruby alaska smoke wildfire pour...       1           9   \n",
       "\n",
       "   unique_word_count  mean_word_len  char_count  \n",
       "0                  7       5.142857          42  \n",
       "1                  7       4.428571          37  \n",
       "2                  9       6.272727          79  \n",
       "3                  7       7.285714          58  \n",
       "4                  9       5.111111          55  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7249803 , 0.67100079, 0.70752858])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model=Model(df1)\n",
    "\n",
    "X=df2[['word_count','unique_word_count','mean_word_len','char_count','modified_text']]\n",
    "y=df2['target']\n",
    "\n",
    "\n",
    "transfomer_numeric = FunctionTransformer(lambda x: x[['word_count','unique_word_count','mean_word_len','char_count']],validate=False)\n",
    "transformer_text = FunctionTransformer(lambda x: x['modified_text'],validate=False)\n",
    "\n",
    "model_union(transfomer_numeric=transfomer_numeric,transformer_text=transformer_text,X=X,y=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "030499805ba0ac5c90ee890a87f8871096ab406f8ecfecc60847e9f6e64db7ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
